{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to write in csv\n",
    "import csv\n",
    "def write_list_in_file(final, name):\n",
    "    with open(name, \"w\", newline=\"\",encoding=\"utf8\") as fp:\n",
    "        a = csv.writer(fp, delimiter=',')\n",
    "        a.writerows(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to read csv files\n",
    "from csv import reader\n",
    "# Load a CSV file\\n\",\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonmoy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype <U9 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#load base data\n",
    "base_data = load_csv('season1.csv')    \n",
    "base_data = np.array(base_data[1:])\n",
    "base_size = len(base_data)\n",
    "\n",
    "#no of target elements and load target data\n",
    "elements = [10,20,30,40,50]\n",
    "target_data = load_csv('season2.csv')\n",
    "target_data = np.array(target_data[1:])\n",
    "\n",
    "#normalize data using a min max normalizer\n",
    "mixed = np.concatenate((base_data,target_data))\n",
    "scaler = MinMaxScaler()\n",
    "mixed_scaled = scaler.fit_transform(mixed)\n",
    "\n",
    "#normalized base and target data\n",
    "base_scaled = mixed_scaled[:base_size]\n",
    "target_scaled = mixed_scaled[base_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of attributes\n",
    "num_attr = mixed_scaled[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Number of Clusters:  7\n"
     ]
    }
   ],
   "source": [
    "#learn number of clusters using silhouette_score\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "num_clusters = 0\n",
    "max_silhouette = -1\n",
    "\n",
    "for n_clusters in range(2,10):\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters)\n",
    "    cluster_labels = clusterer.fit_predict(base_scaled)\n",
    "\n",
    "    silhouette_avg = silhouette_score(base_scaled, cluster_labels)\n",
    "    #print(\"For n_clusters =\", n_clusters,\"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    if(silhouette_avg > max_silhouette):\n",
    "        max_silhouette = silhouette_avg\n",
    "        num_clusters = n_clusters\n",
    "\n",
    "print(\"Optimum Number of Clusters: \",num_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn centers from source/base model\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(base_scaled)\n",
    "\n",
    "base_centroids = kmeans.cluster_centers_\n",
    "#labels = kmeans.labels_\n",
    "    \n",
    "#print(kmeans.cluster_centers_)\n",
    "#print(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying base model in target result:  7.99637305263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonmoy/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:889: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    }
   ],
   "source": [
    "#base model results\n",
    "kmeans = KMeans(n_clusters=num_clusters, init=base_centroids, max_iter=1)\n",
    "kmeans.fit(target_scaled)\n",
    "print(\"applying base model in target result: \", kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining results on  10  data  9.63067393178\n",
      "Retraining results on  20  data  9.25081005174\n",
      "Retraining results on  30  data  6.45792655246\n",
      "Retraining results on  40  data  6.00573365415\n",
      "Retraining results on  50  data  5.92548512222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonmoy/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:889: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    }
   ],
   "source": [
    "#retraining results\n",
    "\n",
    "\n",
    "for n in elements:\n",
    "\n",
    "    #Read Available Limited Target Data\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(target_scaled[:n])\n",
    "    \n",
    "    #Result on whole Target Data\n",
    "    kmeans = KMeans(n_clusters=num_clusters, init=kmeans.cluster_centers_, max_iter=1)\n",
    "    kmeans.fit(target_scaled)\n",
    "\n",
    "    print(\"Retraining results on \", n,\" data \",kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reframing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
