{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to write in csv\n",
    "import csv\n",
    "def write_list_in_file(final, name):\n",
    "    with open(name, \"w\", newline=\"\",encoding=\"utf8\") as fp:\n",
    "        a = csv.writer(fp, delimiter=',')\n",
    "        a.writerows(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to read csv files\n",
    "from csv import reader\n",
    "# Load a CSV file\\n\",\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonmoy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype <U9 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#load base data\n",
    "base_data = load_csv('season1.csv')    \n",
    "base_data = np.array(base_data[1:])\n",
    "base_size = len(base_data)\n",
    "\n",
    "#no of target elements and load target data\n",
    "elements = [10,20,30,40,50]\n",
    "target_data = load_csv('season2.csv')\n",
    "target_data = np.array(target_data[1:])\n",
    "\n",
    "#normalize data using a min max normalizer\n",
    "mixed = np.concatenate((base_data,target_data))\n",
    "scaler = MinMaxScaler()\n",
    "mixed_scaled = scaler.fit_transform(mixed)\n",
    "\n",
    "#normalized base and target data\n",
    "base_scaled = mixed_scaled[:base_size]\n",
    "target_scaled = mixed_scaled[base_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of attributes\n",
    "num_attr = mixed_scaled[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Number of Clusters:  7\n"
     ]
    }
   ],
   "source": [
    "#learn number of clusters using silhouette_score\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "num_clusters = 0\n",
    "max_silhouette = -1\n",
    "\n",
    "for n_clusters in range(2,10):\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters)\n",
    "    cluster_labels = clusterer.fit_predict(base_scaled)\n",
    "\n",
    "    silhouette_avg = silhouette_score(base_scaled, cluster_labels)\n",
    "    #print(\"For n_clusters =\", n_clusters,\"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    if(silhouette_avg > max_silhouette):\n",
    "        max_silhouette = silhouette_avg\n",
    "        num_clusters = n_clusters\n",
    "\n",
    "print(\"Optimum Number of Clusters: \",num_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn centers from source/base model\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(base_scaled)\n",
    "\n",
    "base_centroids = kmeans.cluster_centers_\n",
    "#labels = kmeans.labels_\n",
    "    \n",
    "#print(kmeans.cluster_centers_)\n",
    "#print(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying base model in target result:  7.99637305263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonmoy/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:889: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    }
   ],
   "source": [
    "#base model results\n",
    "kmeans = KMeans(n_clusters=num_clusters, init=base_centroids, max_iter=1)\n",
    "kmeans.fit(target_scaled)\n",
    "print(\"applying base model in target result: \", kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining results on  10  data  9.63067393178\n",
      "Retraining results on  20  data  9.25081005174\n",
      "Retraining results on  30  data  6.45792655246\n",
      "Retraining results on  40  data  6.00573365415\n",
      "Retraining results on  50  data  5.92548512222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonmoy/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:889: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    }
   ],
   "source": [
    "#retraining results\n",
    "\n",
    "\n",
    "for n in elements:\n",
    "\n",
    "    #Read Available Limited Target Data\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(target_scaled[:n])\n",
    "    \n",
    "    #Result on whole Target Data\n",
    "    kmeans = KMeans(n_clusters=num_clusters, init=kmeans.cluster_centers_, max_iter=1)\n",
    "    kmeans.fit(target_scaled)\n",
    "\n",
    "    print(\"Retraining results on \", n,\" data \",kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_centroids(alpha,beta):\n",
    "\n",
    "    target_centroids = []\n",
    "    for i in range(num_clusters):\n",
    "        val = []\n",
    "        for j in range(num_attr):\n",
    "            val.append(alpha[j]*base_centroids[i][j] + beta[j])\n",
    "        \n",
    "        target_centroids.append(val)\n",
    "             \n",
    "\n",
    "    target_centroids = np.array(target_centroids)\n",
    "    print(\"new centroids: \", target_centroids)\n",
    "    return target_centroids\n",
    "    #print(target_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(k,dataItems,centroids,maxIter,num_attr):\n",
    "    \n",
    "    #print(k,dataItems,centroids,maxInter,num_attr)\n",
    "    old_centroids = []\n",
    "    groups = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        groups.append([])\n",
    "        \n",
    "    iter = 0\n",
    "    while(iter < maxIter):\n",
    "        old_centroids = centroids\n",
    "        for item in dataItems:\n",
    "            row = []\n",
    "            for centroid in centroids:\n",
    "                diff = 0\n",
    "                for i in range(num_attr):\n",
    "                    diff += abs(item[i] - centroid[i])\n",
    "                    \n",
    "                row.append(diff)\n",
    "                \n",
    "            idx = row.index(min(row))\n",
    "            groups[idx].append(item)\n",
    "                    \n",
    "            \n",
    "        iter += 1\n",
    "        \n",
    "    ss = 0    \n",
    "    for i in range(k):\n",
    "        for item in groups[i]:\n",
    "            for j in range(num_attr):\n",
    "            \n",
    "                diff = abs(item[j]- old_centroids[i][j])\n",
    "                ss += pow(diff,2)\n",
    "            \n",
    "        \n",
    "    return (groups,ss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_gradient(clusters,reframed_centroids,old_alpha,old_beta):\n",
    "    \n",
    "    gradient_alpha = []\n",
    "    gradient_beta = []\n",
    "    gradient = 0\n",
    "    \n",
    "    for i in range(num_attr):\n",
    "        gradient_alpha.append(0)\n",
    "        gradient_beta.append(0)\n",
    "        \n",
    "    \n",
    "    for i in range(num_clusters):\n",
    "                \n",
    "        for member in clusters[i]:\n",
    "                      \n",
    "            for j in range(num_attr):\n",
    "                \n",
    "                gradient =  (reframed_centroids[i][j] - member[j])\n",
    "                gradient_alpha[j] = gradient_alpha[j] + gradient*reframed_centroids[i][j]\n",
    "                gradient_beta[j] = gradient_beta[j] + gradient\n",
    "\n",
    "    print(\"******\")\n",
    "    #print(gradient_alpha,gradient_beta)\n",
    "    \n",
    "    new_alpha = []\n",
    "    new_beta = []\n",
    "    \n",
    "    for i in range(num_attr):       \n",
    "        new_alpha.append(old_alpha[i]-.01*gradient_alpha[i])\n",
    "        new_beta.append(old_beta[i]-.01*gradient_beta[i])\n",
    "        \n",
    "    return [new_alpha,new_beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99130737776314515, 1.0092333021369835, 1.0133235003375738, 1.084878812312928] [0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "alpha = []\n",
    "beta = []\n",
    "avg_m = []\n",
    "avg_d = []\n",
    "sum_d = 0\n",
    "for i in range(num_attr):\n",
    "    sum_m = 0\n",
    "    for j in range(num_clusters):\n",
    "        sum_m = sum_m + base_centroids[j][i]\n",
    "        \n",
    "    avg_m.append(sum_m/num_clusters)\n",
    "    \n",
    "\n",
    "for i in range(num_attr):\n",
    "    sum_d = 0\n",
    "    for j in range(len(target_scaled[:10])):\n",
    "        sum_d = sum_d + target_scaled[j][i]\n",
    "        \n",
    "    avg_d.append(sum_d/len(target_scaled[:10]))\n",
    "    \n",
    "\n",
    "for i in range(num_attr):\n",
    "    alpha.append(avg_m[i]/avg_d[i])\n",
    "    beta.append(0)\n",
    "\n",
    "print(alpha,beta)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new centroids:  [[ 0.16355839  0.16618691  0.51973753  0.33176255]\n",
      " [ 0.25062838  0.27185965  0.78294091  0.19427337]\n",
      " [ 0.22420695  0.1920063   0.53833174  0.69046429]\n",
      " [ 0.37941289  0.39117382  0.82384862  0.48504881]\n",
      " [ 0.56073282  0.58725431  0.67499621  0.30453968]\n",
      " [ 0.33858762  0.35073781  0.54491268  0.36139946]\n",
      " [ 0.43577614  0.43716693  0.40052711  0.79777621]]\n",
      "best error:  16.5600784138\n",
      "******\n",
      "new alpha beta [1.1192940321919618, 1.1218834262491943, 1.0152502682233744, 1.0716244921632381] [0.23461581771456513, 0.19731735862399774, 0.0031676513432944511, -0.012145656443268909]\n",
      "new centroids:  [[ 0.41929106  0.38205397  0.52389342  0.31556365]\n",
      " [ 0.51760257  0.49952185  0.78759727  0.17975421]\n",
      " [ 0.48776989  0.41075531  0.54252299  0.66988301]\n",
      " [ 0.66301431  0.63215381  0.82858276  0.46697715]\n",
      " [ 0.86774426  0.85012071  0.67944732  0.28867336]\n",
      " [ 0.61691813  0.58720435  0.54911645  0.34483846]\n",
      " [ 0.72665456  0.68328064  0.40445634  0.77588386]]\n",
      "compare  16.5600784138 8.21798731029\n",
      "best error:  8.21798731029\n",
      "******\n",
      "new alpha beta [1.1010402871445735, 1.1380030003853296, 1.026864716881059, 1.0343634177236007] [0.2099097825291372, 0.23349837728964246, 0.025913161424718657, -0.077108014792064597]\n",
      "new centroids:  [[ 0.3915733   0.42088934  0.55259603  0.23920662]\n",
      " [ 0.48828151  0.54004504  0.81931665  0.10811937]\n",
      " [ 0.45893535  0.45000307  0.57143872  0.58120607]\n",
      " [ 0.63132184  0.6745827   0.86077101  0.38535538]\n",
      " [ 0.832713    0.89568141  0.70992946  0.21325133]\n",
      " [ 0.5859774   0.62898739  0.57810761  0.26746354]\n",
      " [ 0.69392422  0.72644414  0.43179259  0.68352121]]\n",
      "compare  8.21798731029 7.71665311466\n",
      "best error:  7.71665311466\n",
      "******\n",
      "new alpha beta [1.1221496954152212, 1.1079260321445761, 1.0230791516185884, 1.0198455842165872] [0.24294909469724618, 0.19757158473296363, 0.030955127387293665, -0.081133685820904883]\n",
      "new centroids:  [[ 0.4280955   0.38000988  0.55569636  0.23074131]\n",
      " [ 0.52665783  0.49601634  0.82143371  0.10149394]\n",
      " [ 0.49674904  0.40835415  0.57446959  0.56794062]\n",
      " [ 0.67244056  0.62699822  0.86273525  0.3748388 ]\n",
      " [ 0.87769284  0.84225338  0.71244978  0.20515031]\n",
      " [ 0.62622677  0.58260798  0.58111389  0.25860162]\n",
      " [ 0.73624317  0.67748898  0.43533827  0.6688197 ]]\n",
      "compare  7.71665311466 7.73379794147\n",
      "finalparameters [1.1010402871445735, 1.1380030003853296, 1.026864716881059, 1.0343634177236007] [0.2099097825291372, 0.23349837728964246, 0.025913161424718657, -0.077108014792064597]\n"
     ]
    }
   ],
   "source": [
    "reframed_centroids =  cal_centroids(alpha,beta)\n",
    "km = kmeans(num_clusters, target_scaled, reframed_centroids, 1, num_attr)\n",
    "#kmeans.fit(target_scaled)\n",
    "best_error = km[1]\n",
    "#centroids = kmeans.cluster_centers_\n",
    "#labels = kmeans.labels_\n",
    "\n",
    "count = 0\n",
    "best_alpha = alpha\n",
    "best_beta = beta\n",
    "while(1):\n",
    "    #print(centroids)\n",
    "    print(\"best error: \",best_error)\n",
    "    \n",
    "    #clusters = find_members(centroids,labels)\n",
    "    \n",
    "    #reframed_centroids = closest_centroids(reframed_centroids,centroids)\n",
    "    \n",
    "    new_alphabeta = cal_gradient(km[0],reframed_centroids,alpha,beta)\n",
    "    \n",
    "    alpha = new_alphabeta[0]\n",
    "    beta = new_alphabeta[1]\n",
    "    \n",
    "    print(\"new alpha beta\", alpha, beta)\n",
    "    \n",
    "    reframed_centroids =  cal_centroids(alpha,beta)\n",
    "    \n",
    "    km = kmeans(num_clusters, target_scaled, reframed_centroids, 1, num_attr)\n",
    "    #kmeans.fit(target_scaled)\n",
    "    new_error = km[1]\n",
    "    \n",
    "    print(\"compare \",best_error,new_error)\n",
    "    if(new_error < best_error):\n",
    "        best_alpha = alpha\n",
    "        best_beta = beta\n",
    "        best_error = new_error\n",
    "        count = 0\n",
    "        \n",
    "    elif(new_error == best_error):\n",
    "        if(count<5):\n",
    "            count += 1\n",
    "            continue\n",
    "        else:\n",
    "            break;\n",
    "                \n",
    "    else:\n",
    "        break; \n",
    "\n",
    "    #base_centroids = kmeans.cluster_centers_\n",
    "    #labels = kmeans.labels_\n",
    "\n",
    "    #print(kmeans.cluster_centers_)\n",
    "    #print(old_error,new_error)\n",
    "    \n",
    "print(\"finalparameters\", best_alpha,best_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new centroids:  [[ 0.3915733   0.42088934  0.55259603  0.23920662]\n",
      " [ 0.48828151  0.54004504  0.81931665  0.10811937]\n",
      " [ 0.45893535  0.45000307  0.57143872  0.58120607]\n",
      " [ 0.63132184  0.6745827   0.86077101  0.38535538]\n",
      " [ 0.832713    0.89568141  0.70992946  0.21325133]\n",
      " [ 0.5859774   0.62898739  0.57810761  0.26746354]\n",
      " [ 0.69392422  0.72644414  0.43179259  0.68352121]]\n"
     ]
    }
   ],
   "source": [
    "target_cent = cal_centroids(best_alpha,best_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.95162535738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonmoy/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:889: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  return_n_iter=True)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters, init=target_cent, max_iter=1)\n",
    "kmeans.fit(target_scaled)\n",
    "print(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
